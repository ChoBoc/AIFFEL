{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4352fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96e8922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100  images to be resized.\n",
      "2100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73edd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114  images to be resized.\n",
      "2114  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "def resize_images1(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images1(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73f495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098  images to be resized.\n",
      "2098  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "def resize_images2(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images2(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d991e49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6312 입니다.\n",
      "x_train shape: (6312, 28, 28, 3)\n",
      "y_train shape: (6312,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=6312):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d01b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e042e87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 127,043\n",
      "Trainable params: 127,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "\n",
    "model10 = keras.models.Sequential()\n",
    "model10.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model10.add(keras.layers.MaxPool2D(2,2))\n",
    "model10.add(keras.layers.Dropout(0.5))\n",
    "model10.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model10.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model10.add(keras.layers.Dropout(0.5))\n",
    "model10.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model10.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model10.add(keras.layers.Dropout(0.5))\n",
    "model10.add(keras.layers.Flatten())\n",
    "model10.add(keras.layers.Dense(256, activation='relu'))\n",
    "model10.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61d3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "198/198 [==============================] - 4s 4ms/step - loss: 1.1005 - accuracy: 0.3425\n",
      "Epoch 2/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 1.0553 - accuracy: 0.4194\n",
      "Epoch 3/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.8582 - accuracy: 0.6058\n",
      "Epoch 4/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.6288 - accuracy: 0.7449\n",
      "Epoch 5/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.7880\n",
      "Epoch 6/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.4791 - accuracy: 0.8081\n",
      "Epoch 7/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.4351 - accuracy: 0.8256\n",
      "Epoch 8/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8474\n",
      "Epoch 9/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.3589 - accuracy: 0.8607\n",
      "Epoch 10/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8626\n",
      "Epoch 11/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.3132 - accuracy: 0.8785\n",
      "Epoch 12/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8744\n",
      "Epoch 13/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2939 - accuracy: 0.8848\n",
      "Epoch 14/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2932 - accuracy: 0.8821\n",
      "Epoch 15/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2683 - accuracy: 0.8958\n",
      "Epoch 16/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.8956\n",
      "Epoch 17/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9000\n",
      "Epoch 18/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.8935\n",
      "Epoch 19/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2556 - accuracy: 0.9016\n",
      "Epoch 20/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2413 - accuracy: 0.9086\n",
      "Epoch 21/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2304 - accuracy: 0.9097\n",
      "Epoch 22/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.9106\n",
      "Epoch 23/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9105\n",
      "Epoch 24/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9171\n",
      "Epoch 25/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9184\n",
      "Epoch 26/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2009 - accuracy: 0.9235\n",
      "Epoch 27/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2195 - accuracy: 0.9167\n",
      "Epoch 28/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2123 - accuracy: 0.9202\n",
      "Epoch 29/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9186\n",
      "Epoch 30/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.2031 - accuracy: 0.9208\n",
      "Epoch 31/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9238\n",
      "Epoch 32/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9262\n",
      "Epoch 33/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9243\n",
      "Epoch 34/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.9298\n",
      "Epoch 35/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9252\n",
      "Epoch 36/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9279\n",
      "Epoch 37/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1902 - accuracy: 0.9254\n",
      "Epoch 38/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9284\n",
      "Epoch 39/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1818 - accuracy: 0.9309\n",
      "Epoch 40/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1728 - accuracy: 0.9325\n",
      "Epoch 41/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9387\n",
      "Epoch 42/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9339\n",
      "Epoch 43/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9369\n",
      "Epoch 44/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9358\n",
      "Epoch 45/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9373\n",
      "Epoch 46/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9404\n",
      "Epoch 47/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9369\n",
      "Epoch 48/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9363\n",
      "Epoch 49/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9419\n",
      "Epoch 50/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9411\n",
      "Epoch 51/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9412\n",
      "Epoch 52/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1579 - accuracy: 0.9401\n",
      "Epoch 53/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9406\n",
      "Epoch 54/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1409 - accuracy: 0.9434\n",
      "Epoch 55/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9444\n",
      "Epoch 56/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9446\n",
      "Epoch 57/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1527 - accuracy: 0.9425\n",
      "Epoch 58/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9480\n",
      "Epoch 59/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9461\n",
      "Epoch 60/60\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f819c6614f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model10.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model10.fit(x_train_norm, y_train, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531ca0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 test이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 test이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 test이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "def resize_images1(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images1(image_dir_path)\n",
    "print(\"바위 test이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "def resize_images2(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images2(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006dd963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.7894 - accuracy: 0.7067\n",
      "test_loss(손실율) = 0.7893516421318054\n",
      "test_accuracy(정확도) = 0.7066666483879089\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "# model10.fit(x_test_norm, y_test, epochs=n_test_epoch)\n",
    "\n",
    "test_loss, test_accuracy = model10.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss(손실율) = {}\".format(test_loss))\n",
    "print(\"test_accuracy(정확도) = {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15583316",
   "metadata": {},
   "source": [
    "### 노드 안에서는 83퍼까지 나왔는데 여기선 낮게 나오네요..ㅠㅠ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
